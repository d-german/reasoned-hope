name: Build and Deploy Writerside to GitHub Pages

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

env:
  # Algolia Search Configuration
  ALGOLIA_APP_ID: "2TVOV323T5"
  ALGOLIA_INDEX_NAME: "reasoned-hope-docs"

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Build Writerside docs using Docker
        uses: JetBrains/writerside-github-action@v4
        with:
          instance: 'Writerside/hi'
          artifact: 'webHelpHI2-all.zip'
          docker-version: '241.18775'

      - name: Save artifact with build results
        uses: actions/upload-artifact@v4
        with:
          name: docs
          path: |
            artifacts/webHelpHI2-all.zip
            artifacts/report.json
          retention-days: 7

  test:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: docs
          path: artifacts

      - name: Test documentation
        uses: JetBrains/writerside-checker-action@v1
        with:
          instance: 'Writerside/hi'

  deploy:
    needs: [build, test]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: docs
          path: artifacts

      - name: Unzip documentation
        run: |
          cd artifacts
          unzip -q webHelpHI2-all.zip -d docs
          ls -la docs/

      - name: Setup Node.js for search integration
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install search dependencies
        run: |
          npm init -y
          npm install algoliasearch cheerio

      - name: Create enhanced indexing script
        run: |
          cat > algolia-indexer.js << 'EOF'
          const { algoliasearch } = require('algoliasearch');
          const fs = require('fs');
          const path = require('path');
          const cheerio = require('cheerio');

          const client = algoliasearch('${{ env.ALGOLIA_APP_ID }}', process.env.ALGOLIA_WRITE_API_KEY);
          const index = client.initIndex('${{ env.ALGOLIA_INDEX_NAME }}');

          async function indexContent() {
            const docsPath = './artifacts/docs';
            const records = [];

            function processHtmlFile(filePath, relativePath) {
              try {
                const content = fs.readFileSync(filePath, 'utf8');
                const $ = cheerio.load(content);

                const title = $('title').text() || $('h1').first().text() || path.basename(relativePath, '.html');

                const sections = [];
                $('h1, h2, h3, h4, h5, h6').each((i, el) => {
                  const heading = $(el);
                  const level = parseInt(el.tagName.substring(1));
                  const headingText = heading.text().trim();

                  if (headingText) {
                    let content = '';
                    let nextEl = heading.next();

                    while (nextEl.length && !nextEl.is('h1, h2, h3, h4, h5, h6')) {
                      const text = nextEl.text().trim();
                      if (text) content += text + ' ';
                      nextEl = nextEl.next();
                    }

                    sections.push({
                      heading: headingText,
                      content: content.trim().substring(0, 800),
                      level: level
                    });
                  }
                });

                if (sections.length === 0) {
                  const bodyText = $('body').text().replace(/\s+/g, ' ').trim();
                  if (bodyText) {
                    sections.push({
                      heading: title,
                      content: bodyText.substring(0, 800),
                      level: 1
                    });
                  }
                }

                sections.forEach((section, index) => {
                  if (section.content) {
                    records.push({
                      objectID: relativePath + '#' + index,
                      title: title,
                      heading: section.heading,
                      content: section.content,
                      url: relativePath.replace(/\\\\/g, '/'),
                      level: section.level,
                      type: 'documentation'
                    });
                  }
                });
              } catch (error) {
                console.warn('Error processing ' + filePath + ':', error.message);
              }
            }

            function walkDirectory(dir, baseDir = dir) {
              const files = fs.readdirSync(dir);

              files.forEach(file => {
                const filePath = path.join(dir, file);
                const stat = fs.statSync(filePath);

                if (stat.isDirectory()) {
                  walkDirectory(filePath, baseDir);
                } else if (file.endsWith('.html') && !file.includes('search.html')) {
                  const relativePath = path.relative(baseDir, filePath);
                  processHtmlFile(filePath, relativePath);
                }
              });
            }

            if (fs.existsSync(docsPath)) {
              console.log('Starting content indexing...');
              walkDirectory(docsPath);

              if (records.length > 0) {
                console.log('Indexing ' + records.length + ' records to Algolia...');
                await index.replaceAllObjects(records);
                console.log('✅ Algolia indexing completed successfully!');
              } else {
                console.log('⚠️ No content found to index.');
              }
            }
          }

          indexContent().catch(error => {
            console.error('❌ Indexing failed:', error);
            process.exit(1);
          });
          EOF

      - name: Index content to Algolia
        if: github.ref == 'refs/heads/main'
        run: node algolia-indexer.js
        env:
          ALGOLIA_WRITE_API_KEY: ${{ secrets.ALGOLIA_WRITE_API_KEY }}

      - name: Copy search files to documentation
        run: |
          # Copy search HTML and JS files if they exist
          if [ -f "Writerside/search.html" ]; then
            cp Writerside/search.html artifacts/docs/
          fi
          if [ -f "Writerside/search-integration.js" ]; then
            cp Writerside/search-integration.js artifacts/docs/
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: artifacts/docs

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
